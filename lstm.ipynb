{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8435e077",
   "metadata": {},
   "source": [
    "# LSTM Model for Cache Hit Prediction\n",
    "\n",
    "This notebook implements a Long Short-Term Memory (LSTM) neural network to predict cache hits based on memory access patterns. The model analyzes sequences of memory addresses to learn patterns that indicate whether a future memory access will result in a cache hit or miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bade637-1eb2-44c5-8360-0a9def7b3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch libraries for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# NumPy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch data utilities\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Advanced dictionary for counting and aggregation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358f0e2",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Importing the necessary libraries:\n",
    "- `torch` and `torch.nn`: PyTorch deep learning framework\n",
    "- `numpy`: For numerical operations\n",
    "- `matplotlib.pyplot`: For plotting and visualization\n",
    "- `DataLoader` and `TensorDataset`: For batching and dataset handling\n",
    "- `defaultdict`: For advanced dictionary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567bf7a1-662a-4961-902f-fb771c068b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the trace file containing memory access data\n",
    "with open(\"test1.out\") as f:\n",
    "    addrs = f.readlines()\n",
    "\n",
    "# Split each line into hit/miss indicator and memory address\n",
    "# The format is: 'hit_count memory_address'\n",
    "hits, addrs = zip(*(l.rstrip().split(' ') for l in addrs))\n",
    "\n",
    "# Convert hit counts to integers\n",
    "hits = [int(hit) for hit in hits]\n",
    "\n",
    "# Convert memory addresses from hex to integers\n",
    "addrs = [int(addr, 16) for addr in addrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ab669",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Loading the cache access data from a file. Each line contains:\n",
    "- A hit/miss indicator (1 for hit, 0 for miss)\n",
    "- A memory address in hexadecimal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3f80de-dd12-48f9-9289-d5ee26aefc36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [536870744,\n",
       "  536870752,\n",
       "  805385384,\n",
       "  805385392,\n",
       "  805385376,\n",
       "  805385400,\n",
       "  536870728,\n",
       "  536870720,\n",
       "  536870712,\n",
       "  536870704])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits[:10], addrs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d421f233-803e-4a40-be26-9983478561c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hit counts to binary target values\n",
    "# Any positive hit count becomes 1, 0 remains 0\n",
    "y = np.asarray(hits)\n",
    "y = (y > 0).astype(np.int_)  # 1 for hit, 0 for miss\n",
    "\n",
    "# Convert memory addresses to feature vectors\n",
    "# TODO: ideally we'd want PCs or to separate address space\n",
    "X = np.asarray(addrs)\n",
    "\n",
    "# Standardize features to have zero mean and unit variance\n",
    "# This is important for neural network training\n",
    "X = (X - X.mean()) / (X.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4e56e",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Preprocessing the data for model training:\n",
    "1. Converting hit counts to binary values (0 = miss, 1 = hit)\n",
    "2. Normalizing memory addresses to have zero mean and unit standard deviation\n",
    "\n",
    "Note: Normalization is crucial for neural network training as it helps with convergence and prevents numerical issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e0a182-079c-406a-bdc7-70fadf3ea5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.05364059, -1.05364053,  0.94539084,  0.9453909 ,  0.94539079,\n",
       "        0.94539096, -1.05364071, -1.05364077, -1.05364083, -1.05364089])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1272f911-3a35-4584-a456-3300764c08c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4a5ac6-df8b-4558-9bc3-75d3aafd1ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09269b9",
   "metadata": {},
   "source": [
    "## Sequence Generation\n",
    "\n",
    "The LSTM model requires sequential data. This function builds sequences of memory addresses (X) with their corresponding future cache hit/miss outcome (y).\n",
    "\n",
    "For each sequence:\n",
    "- Input: n consecutive memory addresses\n",
    "- Target: Whether the n+1 memory access results in a hit or miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce41eb6-ef02-42b8-a79f-92a8e31620a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seqs(X, y, n):\n",
    "    '''\n",
    "    Builds sequences from the dataset for LSTM training.\n",
    "    \n",
    "    Parameters:\n",
    "        X (array): Normalized memory addresses\n",
    "        y (array): Hit/miss indicators (1/0)\n",
    "        n (int): Length of input sequence (window size)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (xs, ys) where:\n",
    "            - xs is an array of input sequences of length n\n",
    "            - ys is an array of corresponding target values\n",
    "    '''\n",
    "    assert len(X) == len(y)\n",
    "    xs = []  # Will hold input sequences\n",
    "    ys = []  # Will hold target values\n",
    "    \n",
    "    # Create sliding windows of size n\n",
    "    for i in range(len(X)-n):\n",
    "        # Extract a sequence of n consecutive addresses\n",
    "        x_sample = X[i:(i+n)]\n",
    "        # Target is whether the next address (after the sequence) results in a hit\n",
    "        y_sample = y[i+n]\n",
    "        xs.append(x_sample)\n",
    "        ys.append(y_sample)\n",
    "        \n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55251ca1-610e-4983-a67a-63d1feea60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences with a window size of 15 addresses\n",
    "# Each sequence contains 15 normalized memory addresses\n",
    "# The target is whether the 16th access is a hit (1) or miss (0)\n",
    "Xs, ys = build_seqs(X, y, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce015dc-cf50-47f9-b9cb-738614eb3aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.05364059, -1.05364053,  0.94539084,  0.9453909 ,  0.94539079,\n",
       "        0.94539096, -1.05364071, -1.05364077, -1.05364083, -1.05364089,\n",
       "        0.9453859 , -1.05364089,  0.94514165,  0.94514207,  0.94514249])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4c9b98-a1e8-4304-be66-83f51872aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44eefb4d-da8e-4aa4-a64f-a6c8397d16dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA-compatible GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6452a8a",
   "metadata": {},
   "source": [
    "## Device Configuration\n",
    "\n",
    "Setting up the computation device - will use GPU (CUDA) if available, otherwise CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303ca5b1-5ae7-49a1-b459-51b0be10c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input sequences (X) to PyTorch tensors\n",
    "# Shape becomes [num_samples, sequence_length, 1] with the added dimension for LSTM input\n",
    "# The None adds a dimension for the feature channel (required by LSTM)\n",
    "trainX = torch.tensor(Xs[:, :, None], dtype=torch.float32).to(device)\n",
    "\n",
    "# Convert target values (y) to PyTorch tensors\n",
    "# Shape becomes [num_samples, 1]\n",
    "trainY = torch.tensor(ys[:, None], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a35b08",
   "metadata": {},
   "source": [
    "## Tensor Conversion\n",
    "\n",
    "Converting NumPy arrays to PyTorch tensors, which are required for model training:\n",
    "- Adding a dimension for the feature channel (required by LSTM)\n",
    "- Moving tensors to the selected device (GPU/CPU)\n",
    "- Setting the appropriate data type (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b7469b3-ba66-49d4-969e-75012db4fe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0536],\n",
       "         [-1.0536],\n",
       "         [ 0.9454],\n",
       "         ...,\n",
       "         [ 0.9451],\n",
       "         [ 0.9451],\n",
       "         [ 0.9451]],\n",
       "\n",
       "        [[-1.0536],\n",
       "         [ 0.9454],\n",
       "         [ 0.9454],\n",
       "         ...,\n",
       "         [ 0.9451],\n",
       "         [ 0.9451],\n",
       "         [-1.0536]],\n",
       "\n",
       "        [[ 0.9454],\n",
       "         [ 0.9454],\n",
       "         [ 0.9454],\n",
       "         ...,\n",
       "         [ 0.9451],\n",
       "         [-1.0536],\n",
       "         [-1.0536]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.0537],\n",
       "         [ 0.9454],\n",
       "         [-1.0537],\n",
       "         ...,\n",
       "         [-1.0537],\n",
       "         [-1.0537],\n",
       "         [-1.0537]],\n",
       "\n",
       "        [[ 0.9454],\n",
       "         [-1.0537],\n",
       "         [ 0.9450],\n",
       "         ...,\n",
       "         [-1.0537],\n",
       "         [-1.0537],\n",
       "         [-1.0537]],\n",
       "\n",
       "        [[-1.0537],\n",
       "         [ 0.9450],\n",
       "         [ 0.9450],\n",
       "         ...,\n",
       "         [-1.0537],\n",
       "         [-1.0537],\n",
       "         [ 0.9454]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9a8db0-28b9-436a-a4ab-9a0beea66c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb329f20-4bc4-4377-bcbb-f9a958c4fa77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4999985, 15, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd008b5",
   "metadata": {},
   "source": [
    "## LSTM Model Definition\n",
    "\n",
    "Defining the Long Short-Term Memory (LSTM) neural network architecture:\n",
    "\n",
    "- **Input**: Sequences of normalized memory addresses\n",
    "- **LSTM Layer**: Processes sequences and captures temporal patterns\n",
    "- **Fully Connected Layer**: Maps LSTM output to binary prediction\n",
    "\n",
    "The model maintains and updates hidden state (h) and cell state (c) between batches for continuous learning on sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fab9eb9-fa9c-42a0-a7a8-227740e26758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        '''\n",
    "        Initialize the LSTM model.\n",
    "        \n",
    "        Parameters:\n",
    "            input_dim (int): Size of input feature dimension (1 for scalar addresses)\n",
    "            hidden_dim (int): Size of the hidden state\n",
    "            layer_dim (int): Number of LSTM layers\n",
    "            output_dim (int): Size of output (1 for binary prediction)\n",
    "        '''\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # LSTM layer with batch_first=True means input shape is [batch, seq, feature]\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to produce output prediction\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        '''\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Parameters:\n",
    "            x (tensor): Input tensor of shape [batch_size, seq_len, input_dim]\n",
    "            h0 (tensor, optional): Initial hidden state\n",
    "            c0 (tensor, optional): Initial cell state\n",
    "            \n",
    "        Returns:\n",
    "            out (tensor): Output predictions\n",
    "            hn (tensor): Final hidden state\n",
    "            cn (tensor): Final cell state\n",
    "        '''\n",
    "        # Initialize hidden states if not provided\n",
    "        if h0 is None or c0 is None:\n",
    "            # Create zero tensors for hidden and cell states\n",
    "            # Shape: [num_layers, batch_size, hidden_dim]\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate the LSTM\n",
    "        # out shape: [batch_size, seq_len, hidden_dim]\n",
    "        # hn and cn shape: [num_layers, batch_size, hidden_dim]\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        # Only take the output from the final timestep\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return self.sigmoid(out), hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6d37d78-5233-4392-905d-74433c0b9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LSTM model\n",
    "# - input_dim=1: Each timestep has a single feature (normalized address)\n",
    "# - hidden_dim=100: Size of the hidden state vector\n",
    "# - layer_dim=1: Single LSTM layer\n",
    "# - output_dim=1: Binary output (hit probability)\n",
    "model = LSTMModel(input_dim=1, hidden_dim=100, layer_dim=1, output_dim=1).to(device)\n",
    "\n",
    "# Define loss function - Mean Squared Error\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer - Adam with learning rate of 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f109714",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Initializing the LSTM model with the following configuration:\n",
    "- Input dimension: 1 (single feature per timestep - normalized address)\n",
    "- Hidden dimension: 100 (size of LSTM cell state)\n",
    "- Layer dimension: 1 (single LSTM layer)\n",
    "- Output dimension: 1 (binary prediction)\n",
    "\n",
    "Also configuring the loss function (Mean Squared Error) and optimizer (Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fb244df-c612-465c-a92e-f7bcadec0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size for training\n",
    "# Larger batch size can speed up training but requires more memory\n",
    "batch_size = 16384\n",
    "\n",
    "# Create PyTorch Dataset from our tensors\n",
    "dataset = TensorDataset(trainX, trainY)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "# - shuffle=True: Randomizes data order in each epoch\n",
    "# - drop_last=True: Drops the last incomplete batch\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ea1f3",
   "metadata": {},
   "source": [
    "## DataLoader Configuration\n",
    "\n",
    "Preparing the data for batch processing using PyTorch's DataLoader:\n",
    "- Creates a TensorDataset from input sequences and target values\n",
    "- Configures the batch size, shuffling, and other training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc1d5c8-b56f-490c-9647-c32a0c1364aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sigmoid.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m x_batch, y_batch = batch\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Forward pass: compute predictions and get new hidden states\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m outputs, h0, c0 = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Calculate batch accuracy (threshold at 0.5 for binary classification)\u001b[39;00m\n\u001b[32m     23\u001b[39m accuracy = ((outputs > \u001b[32m0.5\u001b[39m) == y_batch).sum() / x_batch.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mLSTMModel.forward\u001b[39m\u001b[34m(self, x, h0, c0)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Decode the hidden state of the last time step\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Only take the output from the final timestep\u001b[39;00m\n\u001b[32m     50\u001b[39m out = \u001b[38;5;28mself\u001b[39m.fc(out[:, -\u001b[32m1\u001b[39m, :])\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m, hn, cn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:478\u001b[39m, in \u001b[36mModule.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    473\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() got an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m     )\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    479\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    481\u001b[39m     )\n\u001b[32m    483\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[33;03mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[33;03mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[33;03mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[33;03msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__setattr__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: Sigmoid.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Number of complete passes through the dataset\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize hidden and cell states as None (will be created in first forward pass)\n",
    "h0, c0 = None, None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    # Zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Process each batch in the dataset\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Unpack inputs and targets from batch\n",
    "        x_batch, y_batch = batch\n",
    "        \n",
    "        # Forward pass: compute predictions and get new hidden states\n",
    "        outputs, h0, c0 = model(x_batch, h0, c0)\n",
    "\n",
    "        # Calculate batch accuracy (threshold at 0.5 for binary classification)\n",
    "        accuracy = ((outputs > 0.5) == y_batch).sum() / x_batch.shape[0]\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters based on gradients\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Detach hidden states from the computation graph to prevent \n",
    "        # backpropagation through the entire history (avoids exploding gradients)\n",
    "        h0 = h0.detach()\n",
    "        c0 = c0.detach()\n",
    "        \n",
    "        # Print progress every 10 batches\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {i}, Batch Loss: {loss.item():.4f}, Batch Accuracy {accuracy}\")\n",
    "    \n",
    "    # Alternative epoch-level reporting (commented out)\n",
    "    #print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231d874",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Training the LSTM model with the following process:\n",
    "1. Iterate through epochs\n",
    "2. For each batch in the dataloader:\n",
    "   - Forward pass through the model\n",
    "   - Calculate accuracy and loss\n",
    "   - Backward pass to compute gradients\n",
    "   - Update model parameters\n",
    "\n",
    "Note: The hidden and cell states are preserved between batches but detached from the computation graph to prevent exploding gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f26d2a-25b5-4dc0-8753-fd1ad495e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for model evaluation (uncomment to use)\n",
    "\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     '''\n",
    "#     Evaluate the model on test data\n",
    "#     \n",
    "#     Parameters:\n",
    "#         model: Trained LSTM model\n",
    "#         X_test: Test input sequences\n",
    "#         y_test: Test labels\n",
    "#     \n",
    "#     Returns:\n",
    "#         accuracy: Model accuracy on test data\n",
    "#     '''\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     with torch.no_grad():  # Disable gradient computation\n",
    "#         # Convert test data to tensors\n",
    "#         X_test_tensor = torch.tensor(X_test[:, :, None], dtype=torch.float32).to(device)\n",
    "#         y_test_tensor = torch.tensor(y_test[:, None], dtype=torch.float32).to(device)\n",
    "#         \n",
    "#         # Forward pass\n",
    "#         outputs, _, _ = model(X_test_tensor)\n",
    "#         \n",
    "#         # Calculate accuracy\n",
    "#         predictions = (outputs > 0.5).float()\n",
    "#         accuracy = (predictions == y_test_tensor).sum() / len(y_test_tensor)\n",
    "#     \n",
    "#     return accuracy.item()\n",
    "\n",
    "# # Plot training history\n",
    "# def plot_training_history(history):\n",
    "#     '''\n",
    "#     Plot the training loss and accuracy over epochs\n",
    "#     \n",
    "#     Parameters:\n",
    "#         history: Dictionary containing 'loss' and 'accuracy' lists\n",
    "#     '''\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "#     \n",
    "#     # Plot loss\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(history['loss'])\n",
    "#     plt.title('Training Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     \n",
    "#     # Plot accuracy\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(history['accuracy'])\n",
    "#     plt.title('Training Accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58d5b6",
   "metadata": {},
   "source": [
    "## Model Evaluation and Further Steps\n",
    "\n",
    "After training, the model can be used to predict cache hits for new memory address sequences. Possible next steps:\n",
    "\n",
    "1. **Model Evaluation**: Test the model on a separate validation set to assess generalization performance\n",
    "2. **Hyperparameter Tuning**: Experiment with different LSTM configurations (hidden size, number of layers)\n",
    "3. **Feature Engineering**: Consider additional features like program counter values\n",
    "4. **Visualization**: Plot the training loss and accuracy curves\n",
    "5. **Inference**: Use the trained model to predict cache behavior for new memory traces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
